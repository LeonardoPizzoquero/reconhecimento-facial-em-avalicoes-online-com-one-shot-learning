{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-shot Learning para reconhecimento facial\n",
    "## Projeto final desenvolvido na Escola de Engenharia de Piracicaba - EEP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependências do projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import itertools\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflowjs as tfjs\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, Layer, MaxPooling2D, Dense, Flatten, Input \n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Habilitar GPU para o Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação de pasta base das imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamanho padrão em pixels da imagem de entrada\n",
    "TAMANHO_PADRAO_IMAGEM = 105 \n",
    "\n",
    "DIR_POSITIVAS = os.path.join('data', 'positivas')\n",
    "DIR_NEGATIVAS = os.path.join('data', 'negativas')\n",
    "DIR_ANCORAS = os.path.join('data', 'ancoras')\n",
    "\n",
    "os.makedirs(DIR_POSITIVAS, exist_ok=True)\n",
    "os.makedirs(DIR_NEGATIVAS, exist_ok=True)\n",
    "os.makedirs(DIR_ANCORAS, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LFW - Labeled Faces in the Wild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para imagens negativas utilizamos o seguinte dataset:\n",
    "# http://vis-www.cs.umass.edu/lfw/lfw.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capturar imagens âncoras e positivas com a Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened(): \n",
    "    ret, frame = cap.read()\n",
    "   \n",
    "    # Frame com 250x250 pixels\n",
    "    frame = frame[120:120+250,200:200+250, :]\n",
    "    \n",
    "    # Coletar imagens âncoras pressionando a tecla A do teclado \n",
    "    if cv2.waitKey(1) & 0XFF == ord('a'):\n",
    "        imagem = os.path.join(DIR_ANCORAS, '{}.jpg'.format(uuid.uuid1()))\n",
    "        cv2.imwrite(imagem, frame)\n",
    "    \n",
    "    # Coletar imagens positivas pressionando a tecla P do teclado \n",
    "    if cv2.waitKey(1) & 0XFF == ord('p'):\n",
    "        imagem = os.path.join(DIR_POSITIVAS, '{}.jpg'.format(uuid.uuid1()))\n",
    "        cv2.imwrite(imagem, frame)\n",
    "\n",
    "    cv2.imshow('Coletar imagens', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0XFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(imagem):\n",
    "    data = []\n",
    "    for i in range(40):\n",
    "        imagem = tf.image.stateless_random_jpeg_quality(imagem, min_jpeg_quality=90, max_jpeg_quality=100, seed=(np.random.randint(100),np.random.randint(100)))\n",
    "        imagem = tf.image.stateless_random_brightness(imagem, max_delta=0.02, seed=(1,2))\n",
    "        imagem = tf.image.stateless_random_contrast(imagem, lower=0.6, upper=1, seed=(1,3))\n",
    "        imagem = tf.image.stateless_random_flip_left_right(imagem, seed=(np.random.randint(100),np.random.randint(100)))\n",
    "        imagem = tf.image.stateless_random_saturation(imagem, lower=0.9,upper=1, seed=(np.random.randint(100),np.random.randint(100)))\n",
    "            \n",
    "        data.append(imagem)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando nas imagens positivas\n",
    "for arquivo in os.listdir(os.path.join(DIR_POSITIVAS)):\n",
    "    caminho = os.path.join(DIR_POSITIVAS, arquivo)\n",
    "    img = cv2.imread(caminho)\n",
    "    imagens = data_augmentation(img) \n",
    "    \n",
    "    for imagem in imagens:\n",
    "        cv2.imwrite(os.path.join(DIR_POSITIVAS, '{}.jpg'.format(uuid.uuid1())), imagem.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando nas imagens âncoras\n",
    "for arquivo in os.listdir(os.path.join(DIR_ANCORAS)):\n",
    "    caminho = os.path.join(DIR_ANCORAS, arquivo)\n",
    "    img = cv2.imread(caminho)\n",
    "    imagens = data_augmentation(img) \n",
    "    \n",
    "    for imagem in imagens:\n",
    "        cv2.imwrite(os.path.join(DIR_ANCORAS, '{}.jpg'.format(uuid.uuid1())), imagem.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obter imagens de cada categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positivas = tf.data.Dataset.list_files(DIR_POSITIVAS + '\\*.jpg').take(500) # 500 imagens positivas\n",
    "ancoras = tf.data.Dataset.list_files(DIR_NEGATIVAS + '\\*.jpg').take(500) # 500 imagens âncoras\n",
    "negativas = tf.data.Dataset.list_files(DIR_ANCORAS + '\\*.jpg').take(500) # 500 imagens negativas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerando dataset com pares de imagens positivas e âncoras, negativas e âncoras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pares_negativos = tf.data.Dataset.zip((ancoras, negativas, tf.data.Dataset.from_tensor_slices(tf.zeros(len(ancoras)))))\n",
    "pares_positivos = tf.data.Dataset.zip((ancoras, positivas, tf.data.Dataset.from_tensor_slices(tf.ones(len(ancoras)))))\n",
    "\n",
    "data = pares_positivos.concatenate(pares_negativos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de pré-processamento de imagem de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processamento(caminho):\n",
    "    img = tf.io.read_file(caminho)\n",
    "    imagem = tf.io.decode_jpeg(img)\n",
    "    imagem = tf.image.resize(imagem, (TAMANHO_PADRAO_IMAGEM, TAMANHO_PADRAO_IMAGEM))\n",
    "    imagem = imagem / 255.0\n",
    "    return imagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de pré-processamento dos pares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processamento_siameses(input, validacao, label):\n",
    "    return (pre_processamento(input), pre_processamento(validacao), label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geração dos pares rotulados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(pre_processamento_siameses)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separação de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70% para treino\n",
    "dados_treino = data.take(round(len(data) *.7))\n",
    "dados_treino = dados_treino.batch(16)\n",
    "dados_treino = dados_treino.prefetch(8)\n",
    "\n",
    "# 30% para teste\n",
    "dados_teste = data.skip(round(len(data) *.7))\n",
    "dados_teste = dados_teste.take(round(len(data)*.3))\n",
    "dados_teste = dados_teste.batch(16)\n",
    "dados_teste = dados_teste.prefetch(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação da Rede neural One-shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModeloOneShotLearning(): \n",
    "    # Camada de entrada\n",
    "    input = Input(shape=(TAMANHO_PADRAO_IMAGEM, TAMANHO_PADRAO_IMAGEM, 3), name='input')\n",
    "    # Primeira camada de convolução\n",
    "    conv1 = Conv2D(64, (10,10), activation='relu')(input)\n",
    "    # Primeira camada de max pooling\n",
    "    max1 = MaxPooling2D(64, (2,2), padding='same')(conv1)\n",
    "    # Segunda camada de convolução\n",
    "    conv2 = Conv2D(128, (7,7), activation='relu')(max1)\n",
    "    # Segunda camada de max pooling\n",
    "    max2 = MaxPooling2D(64, (2,2), padding='same')(conv2)\n",
    "    # Terceira camada de convolução\n",
    "    conv3 = Conv2D(128, (4,4), activation='relu')(max2)\n",
    "    # Terceira camada de max pooling\n",
    "    max3 = MaxPooling2D(64, (2,2), padding='same')(conv3)\n",
    "    # Quarta camada de convolução\n",
    "    conv4 = Conv2D(256, (4,4), activation='relu')(max3)\n",
    "    # Unindo dados na camada de flatten para array unidimensional\n",
    "    flatten = Flatten()(conv4)\n",
    "    # Camada densa com ativação sigmoid para classificação binária\n",
    "    densa = Dense(4096, activation='sigmoid')(flatten)\n",
    "\n",
    "    return Model(inputs=[input], outputs=[densa], name='modelo_one_shot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"modelo_one_shot\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 105, 105, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 96, 96, 64)        19264     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 48, 48, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 42, 42, 128)       401536    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 21, 21, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 18, 18, 128)       262272    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 9, 9, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 6, 6, 256)         524544    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              37752832  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,960,448\n",
      "Trainable params: 38,960,448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelo = ModeloOneShotLearning()\n",
    "\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camada customizada para calcular distância L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L1Dist(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "      \n",
    "    def call(self, entrada_img, validacao_img):\n",
    "        return tf.math.abs(entrada_img - validacao_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação da rede neural siamesa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RedeNeuralSiamesa(): \n",
    "    input = Input(name='input', shape=(TAMANHO_PADRAO_IMAGEM, TAMANHO_PADRAO_IMAGEM, 3))\n",
    "    validacao = Input(name='validacao', shape=(TAMANHO_PADRAO_IMAGEM, TAMANHO_PADRAO_IMAGEM, 3))\n",
    "    camada_customizada = L1Dist()\n",
    "    camada_customizada._name = 'distancia_euclidiana'\n",
    "    distancia_euclidiana = camada_customizada(modelo(input), modelo(validacao))\n",
    "    classificador = Dense(1, activation='sigmoid')(distancia_euclidiana)\n",
    "   \n",
    "    return Model(inputs=[input, validacao], outputs=classificador, name='RedeNeuralSiamesa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RedeNeuralSiamesa\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 105, 105, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " validacao (InputLayer)         [(None, 105, 105, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " modelo_one_shot (Functional)   (None, 4096)         38960448    ['input[0][0]',                  \n",
      "                                                                  'validacao[0][0]']              \n",
      "                                                                                                  \n",
      " distancia_euclidiana (L1Dist)  (None, 4096)         0           ['modelo_one_shot[0][0]',        \n",
      "                                                                  'modelo_one_shot[1][0]']        \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            4097        ['distancia_euclidiana[0][0]']   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 38,964,545\n",
      "Trainable params: 38,964,545\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelo_rede_siamesa = RedeNeuralSiamesa()\n",
    "modelo_rede_siamesa.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otimizador e função de custo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cross_loss = tf.losses.BinaryCrossentropy()\n",
    "opt = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo diretório de checkpoints para treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_diretorio = './treino_checkpoints'\n",
    "checkpoint_prefixo = os.path.join(checkpoint_diretorio, 'checkpoint')\n",
    "checkpoint = tf.train.Checkpoint(opt=opt, siamese_model=modelo_rede_siamesa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação da função um passo de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etapa_treino(batch):\n",
    "    # Gravando operações para o cálculo do gradiente\n",
    "    with tf.GradientTape() as tape:     \n",
    "        # Pares\n",
    "        X = batch[:2]\n",
    "        # Rótulos\n",
    "        y = batch[2]\n",
    "        \n",
    "        # Calculando a saída da rede neural\n",
    "        yhat = modelo_rede_siamesa(X, training=True)\n",
    "        # Calculando a perda\n",
    "        loss = binary_cross_loss(y, yhat)\n",
    "        \n",
    "    # Calculando o gradiente\n",
    "    grad = tape.gradient(loss, modelo_rede_siamesa.trainable_variables)\n",
    "    \n",
    "    # Atualizando os pesos da rede neural\n",
    "    opt.apply_gradients(zip(grad, modelo_rede_siamesa.trainable_variables))\n",
    "        \n",
    "    # Retornando a perda\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para treinar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treino(data, EPOCAS):\n",
    "    for epoca in range(1, EPOCAS + 1):\n",
    "        print('\\n Época {}/{}'.format(epoca, EPOCAS))\n",
    "        \n",
    "        progbar = tf.keras.utils.Progbar(len(data))\n",
    "        \n",
    "        r = Recall()\n",
    "        p = Precision()\n",
    "        \n",
    "        for idx, batch in enumerate(data):\n",
    "            loss = etapa_treino(batch)\n",
    "            yhat = modelo_rede_siamesa.predict(batch[:2])\n",
    "            r.update_state(batch[2], yhat)\n",
    "            p.update_state(batch[2], yhat) \n",
    "            progbar.update(idx+1)\n",
    "            \n",
    "        print(loss.numpy(), r.result().numpy(), p.result().numpy())\n",
    "        \n",
    "        # Salvando checkpoint\n",
    "        if epoca % 10 == 0: \n",
    "            checkpoint.save(file_prefix=checkpoint_prefixo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino(dados_treino, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validando precisão e recall em toda base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = Recall()\n",
    "precision = Precision()\n",
    "\n",
    "predicoes = []\n",
    "valores_reais = []\n",
    "\n",
    "for teste_img_input, teste_img_validacao, y_true in dados_teste.as_numpy_iterator():\n",
    "    y_pred = modelo_rede_siamesa.predict([teste_img_input, teste_img_validacao])\n",
    "    recall.update_state(y_true, y_pred)\n",
    "    precision.update_state(y_true, y_pred) \n",
    "    \n",
    "    for predicao in y_pred:\n",
    "        predicoes.append(predicao)\n",
    "        \n",
    "    for valor_real in y_true:\n",
    "        valores_reais.append(valor_real)\n",
    "\n",
    "print(\"Recall:\", recall.result().numpy())\n",
    "print(\"Precision:\", precision.result().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para criar matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "  \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Rótulos verdadeiros')\n",
    "    plt.xlabel('Rótulos preditos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix([1 if predicao > 0.5 else 0 for predicao in predicoes], valores_reais)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confusion, classes=[0, 1],\n",
    "                      title='Matriz de confusão')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeira forma de salvar o modelo com extensão h5\n",
    "modelo_rede_siamesa.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "modelo_rede_siamesa.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando tensorflow.js para salvar o modelo e recarregá-lo na web\n",
    "tfjs.converters.save_keras_model(modelo_rede_siamesa, os.path.join('tfjs_model'))\n",
    "\n",
    "modelo = tf.keras.models.load_model('model.h5', \n",
    "                                   custom_objects={'L1Dist':L1Dist, 'BinaryCrossentropy':tf.losses.BinaryCrossentropy})\n",
    "\n",
    "modelo.save('./model_keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comando para converter o modelo para o formato web com camada customizada\n",
    "!tensorflowjs_converter --input_format=tf_saved_model ./model_keras ./model_web"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
